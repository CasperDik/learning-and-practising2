tutorial yt:
https://youtube.com/playlist?list=PLhTjy8cBISEqkN-5Ku_kXG4QW33sxQo0t

make sure scrapy is installed

create:
-use the terminal and run: "scrapy startproject <projectname>
-create a new python file in the spiders folder
-design your python file with the correct layout

run:
-go to terminal and change directory with "cd <projectname>"
-run in terminal: "scrapy crawl <name of crawler as in python file>"

css tags:
-selector gadget plugin
-click on what you want and then click again on the other items to deselect them
- . for classes

xpath:
-start with //
-example: response.xpath("//span[@class='text']/text()").extract()
-pay attention to double and single quotes --> online when quotation in quotation

store data in containers in python file "items"
--> in the class define the variables to be stored with e.g. author = scrapy.Field()
--> yield the items in parse

--> to store data in e.g. csv, json oid --> use the command "scrapy crawl <projectname> -o <filename>.<filetype>"
e.g. "scrapy crawl quotes -o items.csv"
